{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "DPqlyFdIodqX"
      },
      "outputs": [],
      "source": [
        "text = \"One day, a hare was showing off how fast he could run. \\\n",
        "        He laughed at the turtle for being so slow. After seeing the overconfidence,\\\n",
        "        the turtle moved him to a race. The hare (rabbit) laughed at the turtle's test, \\\n",
        "        and he accepted his demand. As the race began, the rabbit ran extremely quickly\\\n",
        "        and went far ahead of the turtle and got drained. He thought there was a lot of\\\n",
        "        time to relax as the turtle was far away. Soon he slept, thinking he would\\\n",
        "        win the race easily. However, the turtle(tortoise) kept walking slowly until\\\n",
        "        he arrived at the finish line. The rabbit sees the turtle on the opposite side\\\n",
        "        of the finish line. The turtle had won the race. Rabbit laughed the turtle\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "Qwboq-_J2FCF"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class customDataset(Dataset):\n",
        "  def __init__(self, text, word2idx, seq_length):\n",
        "    self.text = text\n",
        "    self.word2idx = word2idx\n",
        "    self.seq_length = seq_length\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.text) - self.seq_length\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    sequence = [self.word2idx[word] for word in self.text[index:index+self.seq_length]]\n",
        "    target = self.word2idx[self.text[index+self.seq_length]]\n",
        "\n",
        "    return torch.tensor(sequence), torch.tensor(target)\n",
        "\n"
      ],
      "metadata": {
        "id": "y2BziMmg2UWT"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx = {word: i for i,word in enumerate(set(text.split()))}\n",
        "idx2word = {i:word for word, i in word2idx.items()}"
      ],
      "metadata": {
        "id": "3e43HI_w2Zws"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = customDataset(text.split(),word2idx,seq_length=10)"
      ],
      "metadata": {
        "id": "lCpQPZ9s2f0R"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-_RpNdZ2l7X",
        "outputId": "118447bc-18b4-47d7-cfc7-5251c3b72720"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 2, 18, 45, 56, 66, 37, 70, 74, 33, 69]), tensor(25))"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "N8yXYod92odG"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMmodel(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_size, hidden_size):\n",
        "    super(LSTMmodel, self).__init__()\n",
        "    self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "    self.lstm = nn.LSTM(embed_size,hidden_size,10,batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size,vocab_size)\n",
        "\n",
        "  def forward(self, x, h0,c0):\n",
        "    embed = self.embed(x)\n",
        "    out,(h_n,c_n) = self.lstm(embed, (h0,c0))\n",
        "    output = self.fc(out[:,-1,:])\n",
        "    return output, (h_n,c_n)"
      ],
      "metadata": {
        "id": "bC3WS2Cn3fy_"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMmodel(len(word2idx),embed_size=128,hidden_size=256 )"
      ],
      "metadata": {
        "id": "fh-nUEXP5Mz8"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr =0.01)"
      ],
      "metadata": {
        "id": "j7NsJsx15Y1T"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "  for input,label in dataloader:\n",
        "    optimizer.zero_grad()\n",
        "    h0 = torch.zeros(10,input.size(0),256)\n",
        "    c0 = torch.zeros(10,input.size(0),256)\n",
        "    outputs, _ = model(input,h0,c0)\n",
        "    loss = criterion(outputs,label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(f\"Epoch {epoch} : Loss : {loss.item()}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcLLMDW95uJJ",
        "outputId": "26337fe8-0edb-40b4-8d5d-d0dc9c9f047c"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 : Loss : 4.353806972503662\n",
            "Epoch 1 : Loss : 4.35554838180542\n",
            "Epoch 2 : Loss : 4.353756904602051\n",
            "Epoch 3 : Loss : 4.369394302368164\n",
            "Epoch 4 : Loss : 4.341869354248047\n",
            "Epoch 5 : Loss : 4.352730751037598\n",
            "Epoch 6 : Loss : 4.34388542175293\n",
            "Epoch 7 : Loss : 4.354694366455078\n",
            "Epoch 8 : Loss : 4.339351654052734\n",
            "Epoch 9 : Loss : 4.328642845153809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = torch.tensor([word2idx[word] for word in text.split()[-10:]]).unsqueeze(0)\n",
        "h0 = torch.zeros(10,input_seq.size(0),256)\n",
        "c0 = torch.zeros(10,input_seq.size(0),256)\n",
        "ouput, _ = model(input_seq,h0,c0)\n",
        "predicted_word = idx2word[ouput.argmax().item()]\n",
        "print(f\"Predicted next word: {predicted_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN6NjQ8J848L",
        "outputId": "651ad291-ec51-4280-aae0-1676564fc11e"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next word: He\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RpgHfGHx9R13"
      },
      "execution_count": 170,
      "outputs": []
    }
  ]
}